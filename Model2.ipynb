{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "IRzbCNMo_-Ds",
        "m2fhdBuLAGIK"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "IRzbCNMo_-Ds"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "j64uCNTb9rrx"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.core.pylabtools import figsize\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
        "from torchvision import datasets, transforms,models\n",
        "import torch.nn as nn\n",
        "from torch.nn.modules.loss import BCEWithLogitsLoss\n",
        "from torch.optim import lr_scheduler\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "from tqdm import tqdm\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import calinski_harabasz_score\n",
        "from torchvision.datasets import ImageFolder\n",
        "import albumentations\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# change directory to the folder where the data is stored\n",
        "%cd /content/drive/My Drive/SAT/project"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAXG7ovi_5Sf",
        "outputId": "786de283-cbb1-4cf4-fcee-de2f82d4b9f3"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/SAT/project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helpers"
      ],
      "metadata": {
        "id": "m2fhdBuLAGIK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_file(zip_path,specified_directory):\n",
        "  with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(specified_directory)"
      ],
      "metadata": {
        "id": "-QuX1VDlAIY4"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_images(flooded_path, non_flooded_path, width, height):\n",
        "    flooded = np.empty((0, width, height, 3))\n",
        "    non_flooded = np.empty((0, width, height, 3))\n",
        "\n",
        "    for filename in os.listdir(flooded_path):\n",
        "        img = cv2.imread(os.path.join(flooded_path, filename), cv2.IMREAD_COLOR)\n",
        "        img = cv2.resize(img, (width, height)) \n",
        "        img = img.astype('float32') / 255.0 \n",
        "        img = np.expand_dims(img, axis=0)\n",
        "        flooded = np.concatenate((flooded, img), axis=0)\n",
        "\n",
        "    for filename in os.listdir(non_flooded_path):\n",
        "        img = cv2.imread(os.path.join(non_flooded_path, filename), cv2.IMREAD_COLOR)\n",
        "        img = cv2.resize(img, (width, height)) \n",
        "        img = img.astype('float32') / 255.0  \n",
        "        img = np.expand_dims(img, axis=0) \n",
        "        non_flooded = np.concatenate((non_flooded, img), axis=0)\n",
        "    return flooded,non_flooded"
      ],
      "metadata": {
        "id": "QxbUlXGGPiMM"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_img(img,title=\"\"):\n",
        "   plt.imshow(img)\n",
        "   plt.title(title)\n",
        "   plt.show()"
      ],
      "metadata": {
        "id": "TJl4e7ZRACKE"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_images(images,images_labels):\n",
        "  nrows = 4\n",
        "  ncols = 4\n",
        "  fig, ax = plt.subplots(nrows,ncols,figsize = (10,10))\n",
        "  ax = ax.flatten()\n",
        "  for i in range(nrows*ncols):\n",
        "      pic = images[i%8]\n",
        "      ax[i].imshow(pic)\n",
        "      ax[i].set_title(images_labels[i%8])\n",
        "      ax[i].set_axis_off()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "zj6qxNPCALRH"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Constants"
      ],
      "metadata": {
        "id": "nOcjFF1zDWB9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CFG = {\n",
        "    'img_size': 256,\n",
        "    'epochs': 10,\n",
        "    'train_bs': 16,\n",
        "    'val_bs': 32,\n",
        "    'test_bs': 32,\n",
        "    'lr': 1e-4,\n",
        "    'freeze': False,\n",
        "    'out_features': 1,\n",
        "    'dataset_path': 'dataset/dataset',\n",
        "    'flooded_path': 'dataset/dataset/flooded',\n",
        "    'non_flooded_path': 'dataset/dataset/non-flooded',\n",
        "    'val_ratio': 0.4,\n",
        "    }"
      ],
      "metadata": {
        "id": "-bVqiMHWDZKy"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the data"
      ],
      "metadata": {
        "id": "C9p2jjDJAOVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# extract_file(\"./dataset.zip\",\"./dataset\")"
      ],
      "metadata": {
        "id": "o9LdXricAMqC"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# flooded, non_flooded = read_images(CFG['flooded_path'], CFG['non_flooded_path'], CFG['img_size'], CFG['img_size'])"
      ],
      "metadata": {
        "id": "99aam6G_CrKS"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(\"flooded images shapes\",flooded.shape)\n",
        "# print(\"non_flooded images shapes\",non_flooded.shape)"
      ],
      "metadata": {
        "id": "oqX60N7DQgeP"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X = np.concatenate((flooded, non_flooded), axis=0)\n",
        "# Y = np.concatenate((np.ones(flooded.shape[0]), np.zeros(non_flooded.shape[0])), axis=0)"
      ],
      "metadata": {
        "id": "xVul1PnwEzN3"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split the dataset"
      ],
      "metadata": {
        "id": "byhMQYTpGIXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Save the array to a file\n",
        "# np.save('X.npy', X)\n",
        "# # Save the array to a file\n",
        "# np.save('Y.npy', Y)"
      ],
      "metadata": {
        "id": "PJDGUV6kWFxo"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the array from the file\n",
        "X = np.load('X.npy')\n",
        "# Load the array from the file\n",
        "Y = np.load('Y.npy')"
      ],
      "metadata": {
        "id": "rRqHvU99Yb7O"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=CFG['val_ratio'], stratify=Y, random_state=42)\n",
        "X_val, X_test, Y_val, Y_test = train_test_split(X_val, Y_val, test_size=0.5, stratify=Y_val, random_state=42)"
      ],
      "metadata": {
        "id": "XMvvVu855Rw-"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  print(X_train.shape, Y_train.shape)  \n",
        "  print(X_val.shape, Y_val.shape)\n",
        "  print(X_test.shape, Y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Lt5ZGh0RRZK",
        "outputId": "43a45eed-49a4-4199-e2d8-5451aafb2a16"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(553, 256, 256, 3) (553,)\n",
            "(184, 256, 256, 3) (184,)\n",
            "(185, 256, 256, 3) (185,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Augmentation"
      ],
      "metadata": {
        "id": "ySQrOftFUNZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train_aug = albumentations.Compose([\n",
        "#             albumentations.RandomResizedCrop(256, 256),\n",
        "#             albumentations.Transpose(p=0.5),\n",
        "#             albumentations.HorizontalFlip(p=0.5),\n",
        "#             albumentations.VerticalFlip(p=0.5),\n",
        "#             albumentations.ShiftScaleRotate(p=0.5),\n",
        "#             albumentations.HueSaturationValue(\n",
        "#                 hue_shift_limit=0.2, \n",
        "#                 sat_shift_limit=0.2, \n",
        "#                 val_shift_limit=0.2, \n",
        "#                 p=0.5\n",
        "#             ),\n",
        "#             albumentations.RandomBrightnessContrast(\n",
        "#                 brightness_limit=(-0.1,0.1), \n",
        "#                 contrast_limit=(-0.1, 0.1), \n",
        "#                 p=0.5\n",
        "#             ),\n",
        "#             # albumentations.Normalize(\n",
        "#             #     mean=[0.485, 0.456, 0.406], \n",
        "#             #     std=[0.229, 0.224, 0.225], \n",
        "#             #     max_pixel_value=255.0, \n",
        "#             #     p=1.0\n",
        "#             # ),\n",
        "#             albumentations.CoarseDropout(p=0.5),\n",
        "#             albumentations.Cutout(p=0.5)\n",
        "#             ], p=1.)\n",
        "  \n",
        "        \n",
        "# val_aug = albumentations.Compose([\n",
        "#             albumentations.CenterCrop(256, 256, p=1.),\n",
        "#             albumentations.Resize(256, 256),\n",
        "#             # albumentations.Normalize(\n",
        "#             #     mean=[0.485, 0.456, 0.406], \n",
        "#             #     std=[0.229, 0.224, 0.225], \n",
        "#             #     max_pixel_value=255.0, \n",
        "#             #     p=1.0\n",
        "#             # )\n",
        "#             ], p=1.)"
      ],
      "metadata": {
        "id": "OWfFDcEJSKDz"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_aug = transforms.Compose([\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            transforms.RandomVerticalFlip(p=0.5),\n",
        "            transforms.RandomRotation(degrees=(-45, 45)),\n",
        "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(\n",
        "                mean=[0.485, 0.456, 0.406],\n",
        "                std=[0.229, 0.224, 0.225],\n",
        "            )\n",
        "        ])\n",
        "\n",
        "val_aug = None"
      ],
      "metadata": {
        "id": "LHzchu4aoW0K"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset and DataLoader"
      ],
      "metadata": {
        "id": "EC8StkDZUuZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# class FloodDataset(Dataset):\n",
        "#     def __init__(self, X, Y, transform=None):\n",
        "#         self.X = torch.from_numpy(X).float()\n",
        "#         self.Y = torch.from_numpy(Y).float()\n",
        "#         # self.X = X\n",
        "#         # self.Y = Y\n",
        "#         self.transform = transform\n",
        "    \n",
        "#     def __len__(self):\n",
        "#         return len(self.X)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         x = self.X[idx]\n",
        "#         y = self.Y[idx]\n",
        "#         if self.transform:\n",
        "#             x = self.transform(x.permute(2, 0, 1))\n",
        "#             # x = self.transform(image=x)['image']\n",
        "#         # x = torch.from_numpy(x).float()\n",
        "#         # y = torch.tensor(y).float()\n",
        "#         return x, y"
      ],
      "metadata": {
        "id": "b7-evE77Sw5N"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_dataset = FloodDataset(X_train, Y_train, train_aug)\n",
        "# val_dataset = FloodDataset(X_val, Y_val, val_aug)\n",
        "# # test_dataset = FloodDataset(X_test, Y_test, None)"
      ],
      "metadata": {
        "id": "iChhK5WAV8Kb"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor = torch.from_numpy(X_train).float()\n",
        "Y_train_tensor = torch.from_numpy(Y_train).float()\n",
        "X_val_tensor = torch.from_numpy(X_val).float()\n",
        "Y_val_tensor = torch.from_numpy(Y_val).float()\n",
        "X_test_tensor = torch.from_numpy(X_test).float()\n",
        "Y_test_tensor = torch.from_numpy(Y_test).float()"
      ],
      "metadata": {
        "id": "8BJUsGeGs3Zh"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = TensorDataset(X_train_tensor, Y_train_tensor)\n",
        "train_dataset.transforms = train_aug\n",
        "\n",
        "val_dataset = TensorDataset(X_val_tensor, Y_val_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, Y_test_tensor)"
      ],
      "metadata": {
        "id": "G1fBAjhssBei"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=CFG['train_bs'], shuffle=True)\n",
        "  val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=CFG['val_bs'], shuffle=True)\n",
        "  test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=CFG['test_bs'], shuffle=True)"
      ],
      "metadata": {
        "id": "iSZrEETEWO-J"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "dvE23A-uY4lF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Resnet(nn.Module):\n",
        "    def __init__(self, pretrained=True, freeze=CFG['freeze'], out_features=CFG['out_features']):\n",
        "        super(Resnet, self).__init__()\n",
        "        self.model = models.resnet18(pretrained=pretrained)\n",
        "        self.model.fc = nn.Linear(self.model.fc.in_features, out_features)\n",
        "\n",
        "        if freeze:\n",
        "            for param in self.model.parameters():\n",
        "                param.requires_grad = False\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "metadata": {
        "id": "R1pSOFTBYlbr"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "NhVc7B2scZ7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, optimizer, criterion, device):\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    running_loss = 0.0\n",
        "    for batch_idx, (input, target) in enumerate(tqdm(train_loader)):\n",
        "            # Get data to cuda if possible\n",
        "            input = input.permute(0, 3, 1, 2)\n",
        "            input = input.to(device=device)\n",
        "            target = target.unsqueeze(1).float()\n",
        "            target = target.to(device=device)\n",
        "\n",
        "            # forward\n",
        "            scores = model(input)\n",
        "            loss = criterion(scores, target)\n",
        "\n",
        "            # backward\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            # gradient descent or adam step\n",
        "            optimizer.step()\n",
        "\n",
        "            predicted = torch.round(torch.sigmoid(scores))\n",
        "            y_true.extend(target.flatten().tolist())\n",
        "            y_pred.extend(predicted.flatten().tolist())\n",
        "\n",
        "    return running_loss/len(train_loader), f1_score(y_true, y_pred, average='macro')"
      ],
      "metadata": {
        "id": "YJuxstGQbLn5"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    running_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "      for batch_idx, (input, target) in enumerate(tqdm(val_loader)):\n",
        "            input = input.permute(0, 3, 1, 2)\n",
        "            input = input.to(device)\n",
        "            target = target.unsqueeze(1).float()\n",
        "            target = target.to(device)\n",
        "\n",
        "            scores = model(input)\n",
        "            loss = criterion(scores, target)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            predicted = torch.round(torch.sigmoid(scores))\n",
        "            y_true.extend(target.flatten().tolist())\n",
        "            y_pred.extend(predicted.flatten().tolist())\n",
        "\n",
        "    return running_loss/len(val_loader), f1_score(y_true, y_pred, average='macro')"
      ],
      "metadata": {
        "id": "nx64CmzncdNY"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run(model, train_loader, val_loader, epochs, device):\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=CFG['lr'])\n",
        "\n",
        "    best_f1 = 0\n",
        "    for epoch in range(epochs):\n",
        "        train_loss, train_f1 = train(model, train_loader, optimizer, criterion, device)\n",
        "        val_loss, val_f1 = evaluate(model, val_loader, criterion, device)\n",
        "        if val_f1 > best_f1:\n",
        "            best_f1 = val_f1\n",
        "            torch.save(model.state_dict(), f\"best_resnet18.pt\")\n",
        "        print(f\"    Training loss: {train_loss} Training macro f1: {100*train_f1:.2f}% Validation loss: {val_loss} Validation macro f1: {100*val_f1:.2f}%\")"
      ],
      "metadata": {
        "id": "mSLtg4CccelN"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "l3nkUFM6ck0m"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  model = Resnet()\n",
        "  model = model.to(device)\n",
        "  acc = run(model, train_loader, val_loader, epochs=20, device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BycxR5kReSrI",
        "outputId": "3099bebf-4511-413d-d11d-b82df0342b77"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "100%|██████████| 35/35 [00:02<00:00, 12.90it/s]\n",
            "100%|██████████| 6/6 [00:00<00:00, 15.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Training loss: 0.24819060316575425 Training macro f1: 92.04% Validation loss: 0.09695737436413765 Validation macro f1: 97.28%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 35/35 [00:02<00:00, 12.75it/s]\n",
            "100%|██████████| 6/6 [00:00<00:00, 15.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Training loss: 0.22556061205520694 Training macro f1: 93.31% Validation loss: 0.05898566544055939 Validation macro f1: 98.91%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 35/35 [00:02<00:00, 12.61it/s]\n",
            "100%|██████████| 6/6 [00:00<00:00, 15.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Training loss: 0.22142943779804877 Training macro f1: 90.05% Validation loss: 0.1582625893255075 Validation macro f1: 94.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 35/35 [00:02<00:00, 12.26it/s]\n",
            "100%|██████████| 6/6 [00:00<00:00, 15.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Training loss: 0.03603482555897374 Training macro f1: 99.10% Validation loss: 0.03386334054327259 Validation macro f1: 98.37%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 35/35 [00:02<00:00, 12.76it/s]\n",
            "100%|██████████| 6/6 [00:00<00:00, 15.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Training loss: 0.005037260562260469 Training macro f1: 99.82% Validation loss: 0.10964824624049167 Validation macro f1: 97.28%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 35/35 [00:02<00:00, 12.69it/s]\n",
            "100%|██████████| 6/6 [00:00<00:00, 15.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Training loss: 0.03154889778067757 Training macro f1: 99.10% Validation loss: 0.07236332601557176 Validation macro f1: 96.19%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 35/35 [00:02<00:00, 12.49it/s]\n",
            "100%|██████████| 6/6 [00:00<00:00, 15.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Training loss: 0.04589555152883155 Training macro f1: 98.55% Validation loss: 0.12448070663958788 Validation macro f1: 96.19%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 35/35 [00:02<00:00, 12.77it/s]\n",
            "100%|██████████| 6/6 [00:00<00:00, 15.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Training loss: 0.015196281071881198 Training macro f1: 99.82% Validation loss: 0.061035146083061896 Validation macro f1: 97.83%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 35/35 [00:02<00:00, 12.76it/s]\n",
            "100%|██████████| 6/6 [00:00<00:00, 15.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Training loss: 0.02272185810096354 Training macro f1: 99.46% Validation loss: 0.2972410172224045 Validation macro f1: 90.68%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 35/35 [00:02<00:00, 12.70it/s]\n",
            "100%|██████████| 6/6 [00:00<00:00, 15.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Training loss: 0.02627021613817695 Training macro f1: 99.10% Validation loss: 0.26463715452700853 Validation macro f1: 91.24%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 35/35 [00:02<00:00, 12.45it/s]\n",
            "100%|██████████| 6/6 [00:00<00:00, 14.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Training loss: 0.019186255098143843 Training macro f1: 99.64% Validation loss: 0.034388295685251556 Validation macro f1: 98.37%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 35/35 [00:02<00:00, 12.57it/s]\n",
            "100%|██████████| 6/6 [00:00<00:00, 15.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Training loss: 0.013799697973549232 Training macro f1: 99.46% Validation loss: 0.0931824103317922 Validation macro f1: 97.28%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 35/35 [00:02<00:00, 12.69it/s]\n",
            "100%|██████████| 6/6 [00:00<00:00, 15.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Training loss: 0.00022901500323127622 Training macro f1: 100.00% Validation loss: 0.0522595943948545 Validation macro f1: 97.83%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 35/35 [00:02<00:00, 12.64it/s]\n",
            "100%|██████████| 6/6 [00:00<00:00, 15.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Training loss: 6.089128119777243e-05 Training macro f1: 100.00% Validation loss: 0.04922806704416871 Validation macro f1: 97.83%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 35/35 [00:02<00:00, 12.35it/s]\n",
            "100%|██████████| 6/6 [00:00<00:00, 14.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Training loss: 3.1168333611982946e-05 Training macro f1: 100.00% Validation loss: 0.04635544405997886 Validation macro f1: 98.37%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 35/35 [00:02<00:00, 12.55it/s]\n",
            "100%|██████████| 6/6 [00:00<00:00, 15.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Training loss: 2.3188011163759776e-05 Training macro f1: 100.00% Validation loss: 0.04445327438755461 Validation macro f1: 98.37%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 35/35 [00:02<00:00, 12.60it/s]\n",
            "100%|██████████| 6/6 [00:00<00:00, 15.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Training loss: 1.97855359396775e-05 Training macro f1: 100.00% Validation loss: 0.04455397931936508 Validation macro f1: 98.37%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 35/35 [00:02<00:00, 12.61it/s]\n",
            "100%|██████████| 6/6 [00:00<00:00, 15.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Training loss: 1.8346669512985566e-05 Training macro f1: 100.00% Validation loss: 0.04425854476100236 Validation macro f1: 98.37%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 35/35 [00:02<00:00, 12.47it/s]\n",
            "100%|██████████| 6/6 [00:00<00:00, 14.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Training loss: 1.4488969522931582e-05 Training macro f1: 100.00% Validation loss: 0.04273349430938348 Validation macro f1: 98.37%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 35/35 [00:02<00:00, 12.52it/s]\n",
            "100%|██████████| 6/6 [00:00<00:00, 15.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Training loss: 1.3098946326956756e-05 Training macro f1: 100.00% Validation loss: 0.048282538734686874 Validation macro f1: 98.37%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Resnet().to(device)\n",
        "model.load_state_dict(torch.load('best_resnet18.pt'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FrXD0qO0YPu",
        "outputId": "b1cdb60e-0fe5-4577-89f0-89c2b09facb2"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "val_loss, val_f1 = evaluate(model, val_loader, criterion, device)\n",
        "print(f\"Validation loss: {val_loss} Validation macro f1: {100*val_f1:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iklYBr4C0sEl",
        "outputId": "8c974195-a5e3-4253-e29b-e3e8b5993cac"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:00<00:00, 15.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 0.060799707348148026 Validation macro f1: 98.91%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "test_loss, test_f1 = evaluate(model, test_loader, criterion, device)\n",
        "print(f\"test loss: {test_loss} test macro f1: {100*test_f1:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFv9GeJ31BbY",
        "outputId": "de8df5bc-502f-4464-a91d-8666f2b37ea1"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:00<00:00, 15.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test loss: 0.054245576883355774 test macro f1: 98.92%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rLqe3xBH1e8u"
      },
      "execution_count": 177,
      "outputs": []
    }
  ]
}